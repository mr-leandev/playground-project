# API stub → model requirements → DB integration (development flow)

This process lets us build full product flows immediately, validate UX and data shapes, then swap the stub storage for a real database with minimal churn.

## 1) Define the contract first
- Write TypeScript models and validation schemas.
- Keep them in a shared module so UI and server reuse the same types.

Example domain model (alerts analysis):

```ts
export type SixFactors = {
  material?: string;
  measurement?: string;
  machine?: string;
  environment?: string;
  people?: string;
  process?: string;
};

export type AlertAnalysis = {
  id: string;                 // alert id
  severity: "info" | "warning" | "critical";
  output?: string;            // general observations (fishbone head)
  factors: SixFactors;        // the 6 factors of production
  updatedAt: string;          // ISO timestamp
  updatedBy?: string;         // user id/email when auth is wired
};
```

Recommended: add Zod schemas for runtime validation and safe parsing at API boundaries.

## 2) Create stub API endpoints (file-backed)
- Route design (stable contract to keep the frontend unchanged later):
  - GET `/api/alerts/[id]/analysis` → `AlertAnalysis | 404`
  - PUT `/api/alerts/[id]/analysis` with body `AlertAnalysis` → `200 { ok: true }`
- Stub storage: JSON file under `.data/alerts.json` (git-ignored). Structure:

```jsonc
{
  "1": {
    "id": "1",
    "severity": "warning",
    "output": "Observed spike above UCL",
    "factors": { "process": "Changeover procedure adjusted" },
    "updatedAt": "2025-08-10T04:10:00Z"
  }
}
```

- Server responsibilities in the stub:
  - Validate payload (Zod) and sanitize strings
  - Read–modify–write the JSON file atomically (fs + temp file then rename)
  - Return typed errors (`400`, `404`, `500`) with a consistent shape

## 3) Wire the UI
- The page loads with GET, populates the form; save triggers PUT.
- Use optimistic UI (disable save during request; show success toast). Persist last-saved state/time.
- Keep the form’s model identical to `AlertAnalysis` to avoid mapping churn later.

## 4) Document the contract
- In `docs/contracts/alerts.analysis.md`, copy the TypeScript, Zod, example requests/responses, and error cases. Treat this as the source of truth.

## 5) Plan the DB schema from the model
Target tables (Supabase/Postgres):
- `alerts` (if not already present): id, org_id, chart_id, point_time, value, rule, created_at
- `alert_analyses`: id (uuid), alert_id (fk), org_id (fk), severity, output text,
  material text, measurement text, machine text, environment text, people text, process text,
  updated_by uuid, updated_at timestamptz

Indexes:
- `alert_analyses(alert_id)`
- `alert_analyses(org_id)`

RLS (row level security):
- Enable on `alert_analyses`
- Policy: user can `select/insert/update` rows where `org_id in (select organization_id from organization_members where user_id = (select auth.uid()))`

Migration notes:
- Start with `alert_analyses`; keep alerts generated by rules (later) in `alerts`.
- Prefer `timestamptz` everywhere; defer timezone rendering to UI.

## 6) Swap stub → Supabase (no UI changes)
- Keep the same HTTP contract and request/response shapes.
- Replace file reads/writes with Supabase queries in the route handlers.
- Add server-side auth (via `@supabase/ssr`) and set `org_id` from the user context; ignore any client-sent `org_id`.

## 7) Fresh Supabase project (recommended for isolation)
- Benefits: freedom to iterate schema and RLS without touching the MVP; safe playground for data.
- Steps when ready:
  1. Create new project in the same org (Dev tier). Generate `NEXT_PUBLIC_SUPABASE_URL` and anon key.
  2. Apply migrations for `alert_analyses` (and any new tables).
  3. Enable RLS; add policies.
  4. Point the Next.js env to the new project; verify SSR queries and route handlers.
  5. Backfill if needed.

## 8) Quality & safety
- Validate on both client and server (Zod).
- Log structured errors in route handlers; redact PII.
- Add integration tests against the stub API; later re-run them against Supabase (same contract).

## 9) Decommission the stub
- Once the DB integration is stable in dev, guard the stub behind `process.env.USE_STUB !== 'true'` and remove it after production cutover.

This flow lets UX and data shape lead the work, while keeping the swap to a real database low-risk and low-cost.
